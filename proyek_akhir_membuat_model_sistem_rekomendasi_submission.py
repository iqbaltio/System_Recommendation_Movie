# -*- coding: utf-8 -*-
"""Proyek Akhir : Membuat Model Sistem Rekomendasi - Submission.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Y8FbQWJ68l0OjAye4f7c4upu41NCObGi

# **Proyek Akhir : Membuat Model Sistem Rekomendasi**

**Nama : Iqbal Tio Ardiansyah**

**Group : M06**

**Memasang kaggle di collab**
"""

!pip install -q kaggle

from google.colab import files
files.upload()

"""**Memberi hak akses pada folder**"""

!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json
!ls ~/.kaggle

"""**Mengunduh data dan unzip data**

**Dataset didapat dari link berikut : https://www.kaggle.com/datasets/satpreetmakhija/netflix-movies-and-tv-shows-2021**
"""

!kaggle datasets download -d harshitshankhdhar/imdb-dataset-of-top-1000-movies-and-tv-shows -p /content/sample_data/ --unzip

"""**Mengimport library yang dibutuhkan**"""

import pandas as pd
import numpy as np 
import string
import matplotlib.pyplot as plt

import seaborn as sns
import re
import textwrap

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from tensorflow import keras

"""**Melihat isi dari data yang sudah kita download**"""

movieData = pd.read_csv('/content/sample_data/imdb_top_1000.csv')
movieData

movieData.describe(include='all')

movieData.info()

"""**Melihat missing values pada data**"""

pd.DataFrame({'Total missing values':movieData.isna().sum()})

"""**Menghapus variabel yang tak digunakan**"""

movieData = movieData.drop(['Poster_Link','Released_Year', 'Runtime', 'Overview', 
                            'Star1', 'Star2', 'Star3', 'Star4', 'No_of_Votes', 'Gross'], axis=1)
movieData.head()

movieData.info()

"""**Keterangan :**

- Series_title : Judul dari film
- Certificate  : Rating umur dari film
- Genre        : Genre film
- IMDB_Rating  : Rating dari situs IMDB
- Meta_score   : Skor yang didapat dari kepuasan penonton
- Director     : Direktor dari film

**Melihat missing value dari data baru kita**
"""

pd.DataFrame({'Total missing values':movieData.isna().sum()})

"""**Menghapus data missing value**"""

movieData = movieData.dropna(subset=['Certificate', 'Meta_score'])
movieData.head()

pd.DataFrame({'Total missing values':movieData.isna().sum()})

movieData.shape

"""**Univariate Data Analysis**"""

movieRating = movieData['Certificate'].value_counts()
sns.barplot(y=movieRating.values,
            x=movieRating.index,).set_title("Rating Movie")
plt.show()

fig, ax = plt.subplots()
sns.distplot(movieData['IMDB_Rating'], ax = ax)
ax.set_xlim(1, 10)
plt.show()

movie_director_count=movieData['Director'].value_counts().sort_values(ascending=False)
movie_director_count=pd.DataFrame(movie_director_count)
topDirector=movie_director_count[1:11]
topDirector

"""**Multivariate Analysis**"""

sns.pairplot(movieData, diag_kind = 'kde')

"""**Text cleaning**"""

movieData['Series_Title'].unique()[5:15]

replace_puncts = {'`': "'", '′': "'", '“':'"', '”': '"', '‘': "'"}

strip_chars = [',', '.', '"', ':', ')', '(', '-', '|', ';', "'", '[', ']', '>', '=', '+', '\\', '•',  '~', '@', 
 '·', '_', '{', '}', '©', '^', '®', '`',  '<', '→', '°', '€', '™', '›',  '♥', '←', '×', '§', '″', '′', 'Â', '█', '½', 'à', '…', 
 '“', '★', '”', '–', '●', 'â', '►', '−', '¢', '²', '¬', '░', '¶', '↑', '±', '¿', '▾', '═', '¦', '║', '―', '¥', '▓', '—', '‹', '─', 
 '▒', '：', '¼', '⊕', '▼', '▪', '†', '■', '’', '▀', '¨', '▄', '♫', '☆', 'é', '¯', '♦', '¤', '▲', 'è', '¸', '¾', 'Ã', '⋅', '‘', '∞', 
 '∙', '）', '↓', '、', '│', '（', '»', '，', '♪', '╩', '╚', '³', '・', '╦', '╣', '╔', '╗', '▬', '❤', 'ï', 'Ø', '¹', '≤', '‡', '√', ]

puncts = ['!', '?', '$', '&', '/', '%', '#', '*','£']

def textCleaning(x):
    x = str(x)
    x = x.lower()
    x = re.sub(r"(https?:\/\/(?:www\.|(?!www))[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\.[^\s]{2,}|www\.[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\.[^\s]{2,}|https?:\/\/(?:www\.|(?!www))[a-zA-Z0-9]\.[^\s]{2,}|www\.[a-zA-Z0-9]\.[^\s]{2,})", "url", x)
    for k, v in replace_puncts.items():
        x = x.replace(k, f' {v} ')
        
    for punct in strip_chars:
        x = x.replace(punct, ' ') 
    
    for punct in puncts:
        x = x.replace(punct, f' {punct} ')
        
    x = x.replace(" '", " ")
    x = x.replace("' ", " ")
    x = x.strip()

    return x

movieData['Series_Title'] = movieData['Series_Title'].apply(textCleaning)

movieData['Series_Title'].unique()[0:15]



"""**Model Development dengan menggunakan Content Based Filtering**

Model yang saya gunakan pada kali ini adalah TF-ID Vectorizer
"""

movieName = movieData['Series_Title'].tolist()
movieGenre = movieData['Genre'].tolist()

print(len(movieName))
print(len(movieGenre))

movieNewData = pd.DataFrame({
    'MovieName': movieName,
    'MovieGenre': movieGenre
})
movieNewData

data = movieNewData
data.sample(5)

tf = TfidfVectorizer()
tf.fit(data['MovieGenre'])
tf.get_feature_names()

tfidf_matrix = tf.fit_transform(data['MovieGenre'])
tfidf_matrix.shape

tfidf_matrix.todense()

pd.DataFrame(
    tfidf_matrix.todense(), 
    columns=tf.get_feature_names(),
    index=data.MovieName
).sample(22, axis=1).sample(10, axis=0)

cosine_sim = cosine_similarity(tfidf_matrix) 
cosine_sim

cosine_sim_df = pd.DataFrame(cosine_sim, index=data['MovieName'], columns=data['MovieName'])
print('Shape:', cosine_sim_df.shape)

cosine_sim_df.sample(5, axis=1).sample(10, axis=0)

def get_Movie_Recommendations(movieName, similarity_data=cosine_sim_df, items=data[['MovieName', 'MovieGenre']], k=10):
    index = similarity_data.loc[:,movieName].to_numpy().argpartition(
        range(-1, -k, -1))
    
    # Mengambil data dengan similarity terbesar dari index yang ada
    closest = similarity_data.columns[index[-1:-(k+2):-1]]
    
    # Drop nama_resto agar nama resto yang dicari tidak muncul dalam daftar rekomendasi
    closest = closest.drop(movieName, errors='ignore')
 
    return pd.DataFrame(closest).merge(items).head(k)

data[data.MovieName.eq('big hero 6')]

get_Movie_Recommendations('big hero 6')

genre_recom = get_Movie_Recommendations('big hero 6')

genre_exp = movieData[movieData['Series_Title'] == 'big hero 6']

genre_exp

get_recom_genre=[]
for i in range(len(genre_exp.Genre)):
    for x in genre_exp.Genre.str.split(','):
        if x not in get_recom_genre:
            get_recom_genre.append(x)

"""**Melihat akurasi dari genre yang direkomendasikan**"""

for i in get_recom_genre[0]:
  print(i + ": " + str((
      (genre_recom['MovieGenre'].str.contains(i).count()/genre_recom['MovieGenre'].count())*100)
  ))

get_Movie_Recommendations('casino royale')

get_Movie_Recommendations('jaws')